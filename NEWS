Noteworthy changes in release a.b
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* Incompatible changes:  Several functions and data types have been changed
  in this release, and the shared library soversion has been bumped.

  - An extra field has been added to the kbitset_t struct so bitsets can
    be made smaller (and later enlarged) without involving memory allocation.

  - A new field has been added to the bam_pileup1_t structure to keep track
    of which CIGAR operator is being processed.  This is used by a new
    bam_plp_insertion() function which can be used to return the sequence of
    any inserted bases at a given pileup location.  If the alignment includes
    CIGAR P operators, the returned sequence will include pads.

  - The hts_itr_t and hts_itr_multi_t structures have been merged and can be
    used interchangeably.  Extra fields have been added to hts_itr_t to support
    this.  hts_itr_multi_t is now a typedef for hts_itr_t; sam_itr_multi_next()
    is now an alias for sam_itr_next() and hts_itr_multi_destroy() is an alias
    for hts_itr_destroy().

  - Elements in the hts_reglist_t structure have been reordered slightly
    so that they pack together better.

  - bgzf_utell() and bgzf_useek() now use type off_t instead of long for
    the offset.  This allows them to work correctly on files longer than
    2G bytes on Windows and 32-bit Linux.

  - A number of functions that used to return void now return int so that
    they can report problems like memory allocation failures.  Callers
    should take care to check the return values from these functions.
    The affected functions are:
       ksort.h:             ks_introsort(), ks_mergesort()
       sam.h:               bam_mplp_init_overlaps()
       synced_bcf_reader.h: bcf_sr_regions_flush()
       vcf.h:               bcf_format_gt(), bcf_fmt_array(),
			    bcf_enc_int1(), bcf_enc_size(),
                            bcf_enc_vchar(), bcf_enc_vfloat(), bcf_enc_vint(),
			    bcf_hdr_set_version(), bcf_hrec_format()
       vcfutils.h:          bcf_remove_alleles()

  - bcf_set_variant_type() now outputs VCF_OVERLAP for spanning
    deletions (ALT=*).

  - A new field (hrecs) has been added to the bam_hdr_t structure for
    use by the new header API.  The old sdict field is now not used and
    marked as deprecated.  The l_text field has been changed from uint32_t
    to size_t, to allow for very large headers in SAM files.  The text
    and l_text fields have been left for backwards compatibility, but
    should not be accessed directly in code that uses the new header API.
    To access the header text, the new functions sam_hdr_length() and
    sam_hdr_str() should be used instead.  The old cigar_tab field is
    now marked as deprecated; use the new bam_cigar_table[] instead.

  - The bam1_core_t structure's l_qname and l_extranul fields have been
    rearranged and enlarged; l_qname still includes the extra NULs.
    (Almost all code should use bam_get_qname(), bam_get_cigar(), etc,
    and has no need to use these fields directly.)  HTSlib now supports
    the SAM specification's full 254 QNAME length again.  (#520)

  - bcf_index_load() no longer tries the '.tbi' suffix when looking for
    BCF index files (.tbi indexes are for text files, not binary BCF).

  - htsFile has a new 'state' member to support SAM multi-threading.

* A new SAM/BAM/CRAM header API has been added to HTSlib, allowing header
  data to be updated without having to parse or rewrite large parts of the
  header text.  See htslib/sam.h for function definitions and documentation.

  The header typedef and several pre-existing functions have been renamed
  to have a sam_hdr_ prefix: sam_hdr_t, sam_hdr_init(), sam_hdr_destroy(),
  and sam_hdr_dup().  (The existing bam_hdr_-prefixed names are still
  provided for compatibility with existing code.)

* SAM format reading and writing is now much faster.  Compared to revision 1.9,
  reading uncompressed SAM may be up to 100% faster; writing up to 80%.  The
  exact improvement depends on which compiler options are used and the
  nature of the SAM file itself.

  The results of parsing invalid SAM files may change due to this update.
  For example some records where the QUAL string is shorter than SEQ
  may report "invalid QUAL character" instead of "SEQ and QUAL are of
  different length".

* The SAM reader and writer can now by run in multi-threaded mode using the
  thread pool.  This means all supported sequence formats (SAM, BAM and CRAM)
  now support multi-threaded reading and writing.

  Note that the multi-threaded SAM reader does not currently support seek
  operations.  Trying to do this (for example with an iterator range request)
  will result in the SAM readers dropping back to single-threaded mode.

* Saving a file with a '.sam.gz' suffix will write BGZF-compressed SAM format.

* hts_detect_format() no longer identifies arbitrary text files as SAM.
  Instead the first few lines are checked for @HD/etc headers or having
  11 or more SAM-like columns.  It also identifies BED/FASTA/FASTQ files
  and several index formats.  (#200, #719, PR #721)

* Empty (0-length) files are no longer considered to be valid SAM files.
  Input files without any headers or records at all are usually seen in
  pipelines such as `somecmd | samtools ...` with `somecmd` aborting and
  outputting nothing, and it is beneficial for the second command to
  propagate the error.  (#261)

* New API functions hts_reglist_create() and sam_itr_regarray() are added
  to create hts_reglist_t region lists from `chr:<from>-<to>` type region
  specifiers.

* An improved region parsing function hts_parse_region() is added.  This
  is designed to help deal with ambiguities that arise when reference names
  contain colons followed by numbers.  It does this by checking possible
  names against the known list of references in the input file.  When even
  this method fails (for example when names "chr1" and "chr1:100-200" both
  exist) the reference name part can be quoted using curly braces.  Thus
  "{chr1}:100-200" and "{chr1:100-200}" disambiguate the above example.

  Specialisations of this function sam_parse_region() and fai_parse_region()
  are also added for SAM/BAM/CRAM files and fasta/fastq files respectively.
  HTSlib iterator functions that accept a region specifier have been
  upgraded to use the new interface.

* hts_idx_load() and hts_open() have been changed to support indexes
  which are not stored in the same location as the indexed file.  This works
  by appending a delimiter '##idx##' and the index file location to the
  normal file name.  hts_open() opens the file in the part before the
  delimiter; hts_idx_load() opens the index in the part after it.  So for
  example, "/path1/my_data.bam##idx##/path2/my_index.csi" will open bam file
  "/path1/my_data.bam" and index file "/path2/my_index.csi".

* New API functions hts_idx_load3(), sam_index_load3(), tbx_index_load3()
  and bcf_index_load3() have been added.  These allow control of whether
  remote indexes should be cached locally, and allow the error message
  printed when the index does not exist to be suppressed.

* hts_idx_load() now checks locally for all possible index names before
  attempting to download a remote index.  It also checks that the remote
  file it downloads is actually an index before trying to save and use
  it.  (https://github.com/samtools/samtools/issues/1045)

* Changes to hfile_s3, which provides support for the AWS S3 API.

  - hfile_s3 now uses version 4 signatures by default.  Attempting to write to
    an S3 bucket will also now work correctly.  It is possible to force
    version 2 signatures by creating environment variable HTS_S3_V2 (the exact
    value does not matter, it just has to exist).  Note that writing depends
    on features that need version 4 signatures, so forcing version 2 will
    disable writes.

  - hfile_s3 will automatically retry requests where the region endpoint
    was not specified correctly, either by following the 301 redirect (when
    using path-style requests) or reading the 400 response (when using
    virtual-hosted style requests and version 4 signatures).  The first
    region to try can be set by using the AWS_DEFAULT_REGION environment
    variable, by setting "region" in ".aws/credentials" or by setting
    "bucket_location" in ".s3cfg".

  - hfile_s3 now percent-escapes the path component of s3:// URLs.  For
    backwards-compatibility it will ignore any paths that have already
    been escaped (detected by looking for '%' followed by two hexadecimal
    digits.)

* Fixed bug where some 8 or 16-bit negative integers were stored using values
  reserved by the BCF specification.  These numbers are now promoted to the
  next size up, so -121 to -128 are stored using at least 16 bits, and -32761
  to -32768 are stored using 32 bits.

  Note that while BCF files affected by this bug are technically incorrect,
  it is still possible to read them.  When converting to VCF format,
  HTSlib (and therefore bcftools) will interpret the values as intended
  and write out the correct negative numbers. (#766, thanks to John Marshall)

* Pileup now correctly reports alignments that begin with a reference skip (N)
  operation.  This fixes a bug where pileup data structures could be left
  in an inconsistent state when trying to process such an alignment.

* Fixed bug where alignments starting 0M could cause an invalid memory access
  in sam_prob_realn().

Noteworthy changes in release 1.9 (18th July 2018)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* If `./configure` fails, `make` will stop working until either configure
  is re-run successfully, or `make distclean` is used.  This makes
  configuration failures more obvious.  (#711, thanks to John Marshall)

* The default SAM version has been changed to 1.6.  This is in line with the
  latest version specification and indicates that HTSlib supports the
  CG tag used to store long CIGAR data in BAM format.

* bgzip integrity check option '--test' (#682, thanks to @sd4B75bJ, @jrayner)

* Faidx can now index fastq files as well as fasta.  The fastq index adds
  an extra column to the `.fai` index which gives the offset to the quality
  values.  New interfaces have been added to `htslib/faidx.h` to read the
  fastq index and retrieve the quality values.  It is possible to open
  a fastq index as if fasta (only sequences will be returned), but not
  the other way round. (#701)

* New API interfaces to add or update integer, float and array aux tags. (#694)

* Add `level=<number>` option to `hts_set_opt()` to allow the compression
  level to be set.  Setting `level=0` enables uncompressed output. (#715)

* Improved bgzip error reporting.

* Better error reporting when CRAM reference files can't be opened. (#706)

* Fixes to make tests work properly on Windows/MinGW - mainly to handle
  line ending differences. (#716)

* Efficiency improvements:

  - Small speed-up for CRAM indexing.

  - Reduce the number of unnecessary wake-ups in the thread pool. (#703)

  - Avoid some memory copies when writing data, notably for uncompressed
    BGZF output. (#703)

* Bug fixes:

  - Fix multi-region iterator bugs on CRAM files. (#684)

  - Fixed multi-region iterator bug that caused some reads to be skipped
    incorrectly when reading BAM files. (#687)

  - Fixed synced_bcf_reader() bug when reading contigs multiple times. (#691,
    reported by @freeseek)

  - Fixed bug where bcf_hdr_set_samples() did not update the sample dictionary
    when removing samples. (#692, reported by @freeseek)

  - Fixed bug where the VCF record ref length was calculated incorrectly
    if an INFO END tag was present. (71b00a)

  - Fixed warnings found when compiling with gcc 8.1.0. (#700)

  - sam_hdr_read() and sam_hdr_write() will now return an error code
    if passed a NULL file pointer, instead of crashing.

  - Fixed possible negative array look-up in sam_parse1() that somehow
    escaped previous fuzz testing. (#731, reported by @fCorleone)

  - Fixed bug where cram range queries could incorrectly report an error
    when using multiple threads. (#734, reported by Brent Pedersen)

  - Fixed very rare rANS normalisation bug that could cause an assertion
    failure when writing CRAM files.  (#739, reported by @carsonhh)

Noteworthy changes in release 1.8 (3rd April 2018)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* The URL to get sequences from the EBI reference server has been changed
  to https://.  This is because the EBI no longer serve sequences via
  plain HTTP - requests to the http:// endpoint just get redirected.
  HTSlib needs to be linked against libcurl to download https:// URLs,
  so CRAM users who want to get references from the EBI will need to
  run configure and ensure libcurl support is enabled using the
  --enable-libcurl option.

* Added libdeflate as a build option for alternative faster compression and
  decompression.  Results vary by CPU but compression should be twice as fast
  and decompression faster.

* It is now possible to set the compression level in bgzip.  (#675; thanks
  to Nathan Weeks).

* bgzip now gets its own manual page.

* CRAM encoding now stored MD and NM tags verbatim where the reference
  contains 'N' characters, to work around ambiguities in the SAM
  specification (samtools #717/762).
  Also added "store_md" and "store_nm" cram-options for forcing these
  tags to be stored at all locations.  This is best when combined with
  a subsequent decode_md=0 option while reading CRAM.

* Multiple CRAM bug fixes, including a fix to free and the subsequent reuse of
  references with `-T ref.fa`. (#654; reported by Chris Saunders)

* CRAM multi-threading bugs fixed: don't try to call flush on reading;
  processing of multiple range queries; problems with multi-slice containers.

* Fixed crashes caused when decoding some cramtools produced CRAM files.

* Fixed a couple of minor rANS issues with handling invalid data.

* Fixed bug where probaln_glocal() tried to allocate far more memory than
  needed when the query sequence was much longer than the reference.  This
  caused crashes in samtools and bcftools mpileup when used on data with very
  long reads. (#572, problem reported by Felix Bemm via minimap2).

* sam_prop_realn() now returns -1 (the same value as for unmapped reads)
  on reads that do not include at least one 'M', 'X' or '=' CIGAR operator,
  and no longer adds BQ or ZQ tags.  BAQ adjustments are only made to bases
  covered by these operators so there is no point in trying to align
  reads that do not have them. (#572)

Noteworthy changes in release 1.7 (26th January 2018)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* BAM: HTSlib now supports BAMs which include CIGARs with more than 
  65535 operations as per HTS-Specs 18th November (dab57f4 and 2f915a8).

* BCF/VCF:
  - Removed the need for long double in pileup calculations.
  - Sped up the synced reader in some situations.
  - Bug fixing: removed memory leak in bcf_copy.

* CRAM:
  - Added support for HTS_IDX_START in cram iterators.
  - Easier to build when lzma header files are absent.
  - Bug fixing: a region query with REQUIRED_FIELDS option to
    disable sequence retrieval now gives correct results.
  - Bug fixing: stop queries to regions starting after the last
    read on a chromosome from incorrectly reporting errors
    (#651, #653; reported by Imran Haque and @egafni via pysam).

* Multi-region iterator: The new structure takes a list of regions and
  iterates over all, deduplicating reads in the process, and producing a 
  full list of file offset intervals. This is usually much faster than 
  repeatedly using the old single-region iterator on a series of regions.

* Curl improvements:
  - Add Bearer token support via HTS_AUTH_LOCATION env (#600).
  - Use CURL_CA_BUNDLE environment variable to override the CA (#622; 
    thanks to Garret Kelly & David Alexander).
  - Speed up (removal of excessive waiting) for both http(s) and ftp.
  - Avoid repeatedly reconnecting by removal of unnecessary seeks.
  - Bug fixing: double free when libcurl_open fails.

* BGZF block caching, if enabled, now performs far better (#629; reported
  by Ram Yalamanchili).

* Added an hFILE layer for in-memory I/O buffers (#590; thanks to Thomas 
  Hickman).

* Tidied up the drand48 support (intended for systems that do not
  provide this function).

Noteworthy changes in release 1.6 (28th September 2017)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* Fixed bug where iterators on CRAM files did not propagate error return
  values to the caller correctly.  Thanks go to Chris Saunders.

* Overhauled Windows builds.  Building with msys2/mingw64 now works
  correctly and passes all tests.

* More improvements to logging output (thanks again to Anders Kaplan).

* Return codes from sam_read1() when reading cram have been made
  consistent with those returned when reading sam/bam.  Thanks to
  Chris Saunders (#575).

* BGZF CRC32 checksums are now always verified.

* It's now possible to set nthreads = 1 for cram files.

* hfile_libcurl has been modified to make it thread-safe.  It's also
  better at handling web servers that do not honour byte range requests
  when attempting to seek - it now sets errno to ESPIPE and keeps
  the existing connection open so callers can revert to streaming mode
  it they want to.

* hfile_s3 now recalculates access tokens if they have become stale.  This
  fixes a reported problem where authentication failed after a file
  had been in use for more than 15 minutes.

* Fixed bug where remote index fetches would fail to notice errors when
  writing files.

* bam_read1() now checks that the query sequence length derived from the
  CIGAR alignment matches the sequence length in the BAM record.

Noteworthy changes in release 1.5 (21st June 2017)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* Added a new logging API: hts_log(), along with hts_log_error(),
  hts_log_warn() etc. convenience macros.  Thanks go to Anders Kaplan
  for the implementation. (#499, #543, #551)

* Added a new file I/O option "block_size" (HTS_OPT_BLOCK_SIZE) to
  alter the hFILE buffer size.

* Fixed various bugs, including compilation issues samtools/bcftools#610,
  samtools/bcftools#611 and robustness to corrupted data #537, #538,
  #541, #546, #548, #549, #554.


Noteworthy changes in release 1.4.1  (8th May 2017)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This is primarily a security bug fix update.

* Fixed SECURITY (CVE-2017-1000206) issue with buffer overruns with malicious data. (#514).

* S3 support for non Amazon AWS endpoints. (#506)

* Support for variant breakpoints in bcftools. (#516)

* Improved handling of BCF NaNs. (#485)

* Compilation / portability improvements. (#255, #423, #498, #488)

* Miscellaneous bug fixes (#482, #521, #522, #523, #524).

* Sanitise headers (#509)


Release 1.4 (13 March 2017)

* Incompatible changes: several functions and data types have been changed
  in this release, and the shared library soversion has been bumped to 2.

  - bam_pileup1_t has an additional field (which holds user data)
  - bam1_core_t has been modified to allow for >64K CIGAR operations
    and (along with bam1_t) so that CIGAR entries are aligned in memory
  - hopen() has vararg arguments for setting URL scheme-dependent options
  - the various tbx_conf_* presets are now const
  - auxiliary fields in bam1_t are now always stored in little-endian byte
    order (previously this depended on if you read a bam, sam or cram file)
  - index metadata (accessible via hts_idx_get_meta()) is now always
    stored in little-endian byte order (previously this depended on if
    the index was in tbi or csi format)
  - bam_aux2i() now returns an int64_t value
  - fai_load() will no longer save local copies of remote fasta indexes
  - hts_idx_get_meta() now takes a uint32_t * for l_meta (was int32_t *)

* HTSlib now links against libbz2 and liblzma by default.  To remove these
  dependencies, run configure with options --disable-bz2 and --disable-lzma,
  but note that this may make some CRAM files produced elsewhere unreadable. 

* Added a thread pool interface and replaced the bgzf multi-threading
  code to use this pool.  BAM and CRAM decoding is now multi-threaded
  too, using the pool to automatically balance the number of threads
  between decode, encode and any data processing jobs.

* New errmod_cal(), probaln_glocal(), sam_cap_mapq(), and sam_prob_realn()
  functions, previously internal to SAMtools, have been added to HTSlib.

* Files can now be accessed via Google Cloud Storage using gs: URLs, when
  HTSlib is configured to use libcurl for network file access rather than
  the included basic knetfile networking.

* S3 file access now also supports the "host_base" setting in the
  $HOME/.s3cfg configuration file.

* Data URLs ("data:,text") now follow the standard RFC 2397 format and may
  be base64-encoded (when written as "data:;base64,text") or may include
  percent-encoded characters.  HTSlib's previous over-simplified "data:text"
  format is no longer supported -- you will need to add an initial comma.

* When plugins are enabled, S3 support is now provided by a separate
  hfile_s3 plugin rather than by hfile_libcurl itself as previously.
  When --enable-libcurl is used, by default both GCS and S3 support
  and plugins will also be built; they can be individually disabled
  via --disable-gcs and --disable-s3.

* The iRODS file access plugin has been moved to a separate repository.
  Configure no longer has a --with-irods option; instead build the plugin
  found at <https://github.com/samtools/htslib-plugins>.

* APIs to portably read and write (possibly unaligned) data in little-endian
  byte order have been added.

* New functions bam_auxB_len(), bam_auxB2i() and bam_auxB2f() have been
  added to make accessing array-type auxiliary data easier.  bam_aux2i()
  can now return the full range of values that can be stored in an integer
  tag (including unsigned 32 bit tags).  bam_aux2f() will return the value
  of integer tags (as a double) as well as floating-point ones.  All of
  the bam_aux2 and bam_auxB2 functions will set errno if the requested
  conversion is not valid.

* New functions fai_load3() and fai_build3() allow fasta indexes to be
  stored in a different location to the indexed fasta file.

* New functions bgzf_index_dump_hfile() and bgzf_index_load_hfile()
  allow bgzf index files (.gzi) to be written to / read from an existing
  hFILE handle.

* hts_idx_push() will report when trying to add a range to an index that
  is beyond the limits that the given index can handle.  This means trying
  to index chromosomes longer than 2^29 bases with a .bai or .tbi index
  will report an error instead of apparantly working but creating an invalid
  index entry.

* VCF formatting is now approximately 4x faster.  (Whether this is
  noticable depends on what was creating the VCF.)

* CRAM lossy_names mode now works with TLEN of 0 or TLEN within +/- 1
  of the computed value.  Note in these situations TLEN will be
  generated / fixed during CRAM decode.

* CRAM now supports bzip2 and lzma codecs.  Within htslib these are
  disabled by default, but can be enabled by specifying "use_bzip2" or
  "use_lzma" in an hts_opt_add() call or via the mode string of the
  hts_open_format() function.

Noteworthy changes in release 1.3.2  (13 September 2016)

* Corrected bin calculation when converting directly from CRAM to BAM.
  Previously a small fraction of converted reads would fail Picard's
  validation with "bin field of BAM record does not equal value computed"
  (SAMtools issue #574).

* Plugins can now signal to HTSlib which of RTLD_LOCAL and RTLD_GLOBAL
  they wish to be opened with -- previously they were always RTLD_LOCAL.


Noteworthy changes in release 1.3.1  (22 April 2016)

* Improved error checking and reporting, especially of I/O errors when
  writing output files (#17, #315, PR #271, PR #317).

* Build fixes for 32-bit systems; be sure to run configure to enable
  large file support and access to 2GiB+ files.

* Numerous VCF parsing fixes (#321, #322, #323, #324, #325; PR #370).
  Particular thanks to Kostya Kortchinsky of the Google Security Team
  for testing and numerous input parsing bug reports.

* HTSlib now prints an informational message when initially creating a
  CRAM reference cache in the default location under your $HOME directory.
  (No message is printed if you are using $REF_CACHE to specify a location.)

* Avoided rare race condition when caching downloaded CRAM reference sequence
  files, by using distinctive names for temporary files (in addition to O_EXCL,
  which has always been used).  Occasional corruption would previously occur
  when multiple tools were simultaneously caching the same reference sequences
  on an NFS filesystem that did not support O_EXCL (PR #320).

* Prevented race condition in file access plugin loading (PR #341).

* Fixed mpileup memory leak, so no more "[bam_plp_destroy] memory leak [...]
  Continue anyway" warning messages (#299).

* Various minor CRAM fixes.

* Fixed documentation problems #348 and #358.


Noteworthy changes in release 1.3  (15 December 2015)

* Files can now be accessed via HTTPS and Amazon S3 in addition to HTTP
  and FTP, when HTSlib is configured to use libcurl for network file access
  rather than the included basic knetfile networking.

* HTSlib can be built to use remote access hFILE backends (such as iRODS
  and libcurl) via a plugin mechanism.  This allows other backends to be
  easily added and facilitates building tools that use HTSlib, as they
  don't need to be linked with the backends' various required libraries.

* When writing CRAM output, sam_open() etc now default to writing CRAM v3.0
  rather than v2.1.

* fai_build() and samtools faidx now accept initial whitespace in ">"
  headers (e.g., "> chr1 description" is taken to refer to "chr1").

* tabix --only-header works again (was broken in 1.2.x; #249).

* HTSlib's configure script and Makefile now fully support the standard
  convention of allowing CC/CPPFLAGS/CFLAGS/LDFLAGS/LIBS to be overridden
  as needed.  Previously the Makefile listened to $(LDLIBS) instead; if you
  were overriding that, you should now override LIBS rather than LDLIBS.

* Fixed bugs #168, #172, #176, #197, #206, #225, #245, #265, #295, and #296.


Noteworthy changes in release 1.2.1  (3 February 2015)

* Reinstated hts_file_type() and FT_* macros, which were available until 1.1
  but briefly removed in 1.2.  This function is deprecated and will be removed
  in a future release -- you should use hts_detect_format() etc instead


Noteworthy changes in release 1.2  (2 February 2015)

* HTSlib now has a configure script which checks your build environment
  and allows for selection of optional extras.  See INSTALL for details

* By default, reference sequences are fetched from the EBI CRAM Reference
  Registry and cached in your $HOME cache directory.  This behaviour can
  be controlled by setting REF_PATH and REF_CACHE enviroment variables
  (see the samtools(1) man page for details)

* Numerous CRAM improvements:
  - Support for CRAM v3.0, an upcoming revision to CRAM supporting
    better compression and per-container checksums
  - EOF checking for v2.1 and v3.0 (similar to checking BAM EOF blocks)
  - Non-standard values for PNEXT and TLEN fields are now preserved
  - hts_set_fai_filename() now provides a reference file when encoding
  - Generated read names are now numbered from 1, rather than being
    labelled 'slice:record-in-slice'
  - Multi-threading and speed improvements

* New htsfile command for identifying file formats, and corresponding
  file format detection APIs

* New tabix --regions FILE, --targets FILE options for filtering via BED files

* Optional iRODS file access, disabled by default.  Configure with --with-irods
  to enable accessing iRODS data objects directly via 'irods:DATAOBJ'

* All occurences of 2^29 in the source have been eliminated, so indexing
  and querying against reference sequences larger than 512Mbp works (when
  using CSI indices)

* Support for plain GZIP compression in various places

* VCF header editing speed improvements

* Added seq_nt16_int[] (equivalent to the samtools API's bam_nt16_nt4_table)

* Reinstated faidx_fetch_nseq(), which was accidentally removed from 1.1.
  Now faidx_fetch_nseq() and faidx_nseq() are equivalent; eventually
  faidx_fetch_nseq() will be deprecated and removed [#156]

* Fixed bugs #141, #152, #155, #158, #159, and various memory leaks
